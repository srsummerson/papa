{
 "metadata": {
  "name": "",
  "signature": "sha256:592f88061d5dd20991c426173ce025abefff6876290ebe3c09c4cb5b6cd2fe5c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Uses sham data from Feb 10 - March 10.  Using GLM "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd C:\\Users\\Samantha\\Dropbox\\Carmena Lab\\Papa\\hdf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import numpy as np\n",
      "import statsmodels.api as sm\n",
      "import scipy\n",
      "import matplotlib.pyplot as plt\n",
      "import tables\n",
      "from pylab import rcParams\n",
      "import pandas as pd\n",
      "from patsy import dmatrices\n",
      "from sklearn.linear_model import LogisticRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#hdf_list = ['papa20150213_10.hdf','papa20150217_05.hdf','papa20150225_02.hdf','papa20150301_02.hdf','papa20150305_02.hdf',\n",
      "#            'papa20150307_02.hdf','papa20150308_06.hdf','papa20150310_02.hdf']\n",
      "#hdf_list with days where learning in block A was not sufficient are excluded\n",
      "hdf_list = ['papa20150213_10.hdf','papa20150217_05.hdf','papa20150225_02.hdf','papa20150305_02.hdf',\n",
      "            'papa20150307_02.hdf','papa20150308_06.hdf','papa20150310_02.hdf']\n",
      "counter = 0\n",
      "it_side = []\n",
      "it_reward = []\n",
      "fc_low_side = []\n",
      "fc_target = []\n",
      "for name in hdf_list:\n",
      "    hdf = tables.openFile(name)\n",
      "\n",
      "    # states\n",
      "    state = hdf.root.task_msgs[:]['msg']\n",
      "    state_time = hdf.root.task_msgs[:]['time']\n",
      "    # target info: (offset, probability of reward, left/right)\n",
      "    targetH = hdf.root.task[:]['targetH']\n",
      "    targetL = hdf.root.task[:]['targetL']\n",
      "    # reward schedules\n",
      "    reward_scheduleH = hdf.root.task[:]['reward_scheduleH']\n",
      "    reward_scheduleL = hdf.root.task[:]['reward_scheduleL']\n",
      "    # instructed (1) or free-choice (2) trial \n",
      "    trial_type = hdf.root.task[:]['target_index']\n",
      "\n",
      "    ind_wait_states = np.ravel(np.nonzero(state == 'wait'))\n",
      "    ind_target_states = np.ravel(np.nonzero(state == 'target'))\n",
      "    ind_check_reward_states = np.ravel(np.nonzero(state == 'check_reward'))\n",
      "    num_successful_trials = ind_check_reward_states.size\n",
      "    target_times = state_time[ind_target_states]\n",
      "    # creates vector same size of state vectors for comparison. instructed (0) and free-choice (1)\n",
      "    instructed_or_freechoice = trial_type[state_time[ind_check_reward_states]]  \n",
      "    num_free_choice_trials = sum(instructed_or_freechoice) - num_successful_trials\n",
      "\n",
      "    # creates vector of same size of target info: maxtrix of num_successful_trials x 3; (position_offset, reward_prob, left0/right1)\n",
      "    targetH_info = targetH[state_time[ind_target_states]]\n",
      "    targetL_info = targetL[state_time[ind_target_states]]\n",
      "    #counter = 0\n",
      "    #it_side = []\n",
      "    #it_reward = []\n",
      "    #fc_low_side = []\n",
      "    #fc_target = []\n",
      "\n",
      "    for i in range(200,num_successful_trials):\n",
      "        target_state = state[ind_check_reward_states[i] - 2]\n",
      "        #trial = trial_type[state_time[ind_check_reward_states[i] -2]]\n",
      "        trial = instructed_or_freechoice[i]\n",
      "        previous_trial = instructed_or_freechoice[i-1]\n",
      "        if target_state == 'hold_targetL':\n",
      "            target_all_block3 = 1\n",
      "        else:\n",
      "            target_all_block3 = 0  # rather than 2, indicates low value target was not selected\n",
      "\n",
      "        if (trial == 2) and (previous_trial ==1):\n",
      "            it_side.append(targetL_info[i-1][2])   # postion info for previous instructed low value target\n",
      "            it_reward.append(state[ind_check_reward_states[i-1]+1] == 'reward')  # reward for previous instructed low value target\n",
      "            fc_low_side.append(targetL_info[i][2]) # what side low value target is presented on in free choice trial\n",
      "            fc_target.append(target_all_block3)  # what target is selected: 1 = low value, 2 = high value\n",
      "            #it_side = np.append(it_side,targetL_info[i-1][2])   # postion info for previous instructed low value target\n",
      "            #it_reward = np.append(it_reward,state[ind_check_reward_states[i]+1] == 'reward')  # reward for previous instructed low value target\n",
      "            #fc_low_side = np.append(fc_low_side,targetL_info[i][2]) # what side low value target is presented on in free choice trial\n",
      "            #fc_target = np.append(fc_target,target_all_block3)  # what target is selected: 1 = low value, 2 = high value\n",
      "            counter += 1\n",
      "\n",
      "y = np.array(fc_target)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "it_side = np.array(it_side)\n",
      "it_reward = np.array(1*it_reward)\n",
      "fc_low_side = np.array(fc_low_side)\n",
      "const_logit = np.ones(it_side.size)\n",
      "x = np.vstack((it_side,it_reward,fc_low_side))\n",
      "x = np.transpose(x)\n",
      "x = sm.add_constant(x,prepend='False')\n",
      "#x = sm.add_constant(x,prepend=\"False\")\n",
      "d = {'FC Target Selection' : fc_target, 'IT Side' : it_side, 'IT Reward' : it_reward, 'FC Low Target Side' : fc_low_side, 'Const' : const_logit}\n",
      "\n",
      "df = pd.DataFrame(d)\n",
      "\n",
      "model_glm = sm.GLM(fc_target, x, family=sm.families.Binomial())\n",
      "\n",
      "fit_glm = model_glm.fit()\n",
      "fit_glm.summary()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "explanatory_cols = df.columns[[0,1,3,4]]\n",
      "dependent_col = df.columns[2]\n",
      "\n",
      "logit = sm.Logit(df[dependent_col], df[explanatory_cols])\n",
      "#probit_model = sm.Probit(df[dependent_col], df[explanatory_cols])\n",
      " \n",
      "# fit the model\n",
      "result = logit.fit()\n",
      "result.summary()\n",
      "#result_probit = probit_model.fit()\n",
      "#result_probit.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None)\n",
      "model = model.fit(df[explanatory_cols], df[dependent_col])\n",
      "\n",
      "# check the accuracy on the training set\n",
      "model.score(df[explanatory_cols], df[dependent_col])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame(zip(explanatory_cols, np.transpose(model.coef_)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}