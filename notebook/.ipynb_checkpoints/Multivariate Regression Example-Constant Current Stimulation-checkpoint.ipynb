{
 "metadata": {
  "name": "",
  "signature": "sha256:f16f78f2a81d86cca5e91e1ebd5936f6a926bb986f9eefac68d475e5311fbb89"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Note: this data is not a good test for multivariate regression since the dependent variable is binary.  However, this is a good documentation of the steps taken to do linear regression in Python."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Multivariate regression for first free-choice (FC) trial selection following an instructed-choice (IC) trial with stimulation for the first 100 trials within Block A'.  Results show that the low value target being on the right hand side is positively correlated with the selection of the it in the FC trial.  However, the location of the target in the IC trial was not correlated with the selection of the low value target in the following FC tree and neither was the IC trial having a reward associated with it. \n",
      "\n",
      "It's important to note that the resulting model is not a good fit - the explanatory variables explain roughly 5% of the variance of the dependent variable."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "If you consider all trials in Block A' (rather than the first 100), there is no longer a correlation between the side of the low value target and whether it's selected in the FC trial.  However, there is a signiciant postive correlation between whether the low value target is rewarded in the instructed trial and if it's selected in the FC trial."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd C:\\Users\\Samantha\\Dropbox\\Carmena Lab\\Papa\\hdf\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\Samantha\\Dropbox\\Carmena Lab\\Papa\\hdf\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "import numpy as np\n",
      "import statsmodels.api as sm\n",
      "import scipy\n",
      "import matplotlib.pyplot as plt\n",
      "import tables\n",
      "import numpy\n",
      "from pylab import rcParams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\pandas\\computation\\expressions.py:21: UserWarning: The installed version of numexpr 2.0.1 is not supported in pandas and will be not be used\n",
        "The minimum supported version is 2.1\n",
        "\n",
        "  \"version is 2.1\\n\".format(ver=ver), UserWarning)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hdf_list = ['papa20150210_13.hdf','papa20150211_11.hdf','papa20150214_18.hdf','papa20150216_05.hdf','papa20150218_04.hdf','papa20150219_09.hdf','papa20150223_02.hdf','papa20150224_02.hdf']\n",
      "counter = 0\n",
      "it_side = []\n",
      "it_reward = []\n",
      "fc_low_side = []\n",
      "fc_target = []\n",
      "for name in hdf_list:\n",
      "    hdf = tables.openFile(name)\n",
      "\n",
      "    # states\n",
      "    state = hdf.root.task_msgs[:]['msg']\n",
      "    state_time = hdf.root.task_msgs[:]['time']\n",
      "    # target info: (offset, probability of reward, left/right)\n",
      "    targetH = hdf.root.task[:]['targetH']\n",
      "    targetL = hdf.root.task[:]['targetL']\n",
      "    # reward schedules\n",
      "    reward_scheduleH = hdf.root.task[:]['reward_scheduleH']\n",
      "    reward_scheduleL = hdf.root.task[:]['reward_scheduleL']\n",
      "    # instructed (1) or free-choice (2) trial \n",
      "    trial_type = hdf.root.task[:]['target_index']\n",
      "\n",
      "    ind_wait_states = np.ravel(np.nonzero(state == 'wait'))\n",
      "    ind_target_states = np.ravel(np.nonzero(state == 'target'))\n",
      "    ind_check_reward_states = np.ravel(np.nonzero(state == 'check_reward'))\n",
      "    num_successful_trials = ind_check_reward_states.size\n",
      "    target_times = state_time[ind_target_states]\n",
      "    # creates vector same size of state vectors for comparison. instructed (0) and free-choice (1)\n",
      "    instructed_or_freechoice = trial_type[state_time[ind_check_reward_states]]  \n",
      "    num_free_choice_trials = sum(instructed_or_freechoice) - num_successful_trials\n",
      "\n",
      "    # creates vector of same size of target info: maxtrix of num_successful_trials x 3; (position_offset, reward_prob, left0/right1)\n",
      "    targetH_info = targetH[state_time[ind_target_states]]\n",
      "    targetL_info = targetL[state_time[ind_target_states]]\n",
      "    #counter = 0\n",
      "    #it_side = []\n",
      "    #it_reward = []\n",
      "    #fc_low_side = []\n",
      "    #fc_target = []\n",
      "\n",
      "    for i in range(200,300):\n",
      "        target_state = state[ind_check_reward_states[i] - 2]\n",
      "        #trial = trial_type[state_time[ind_check_reward_states[i] -2]]\n",
      "        trial = instructed_or_freechoice[i]\n",
      "        previous_trial = instructed_or_freechoice[i-1]\n",
      "        if target_state == 'hold_targetL':\n",
      "            target_all_block3 = 1\n",
      "        else:\n",
      "            target_all_block3 = 0  # rather than 2, indicates low value target was not selected\n",
      "\n",
      "        if (trial == 2) and (previous_trial ==1):\n",
      "            it_side.append(targetL_info[i-1][2])   # postion info for previous instructed low value target\n",
      "            it_reward.append(state[ind_check_reward_states[i-1]+1] == 'reward')  # reward for previous instructed low value target\n",
      "            fc_low_side.append(targetL_info[i][2]) # what side low value target is presented on in free choice trial\n",
      "            fc_target.append(target_all_block3)  # what target is selected: 1 = low value, 2 = high value\n",
      "            #it_side = np.append(it_side,targetL_info[i-1][2])   # postion info for previous instructed low value target\n",
      "            #it_reward = np.append(it_reward,state[ind_check_reward_states[i]+1] == 'reward')  # reward for previous instructed low value target\n",
      "            #fc_low_side = np.append(fc_low_side,targetL_info[i][2]) # what side low value target is presented on in free choice trial\n",
      "            #fc_target = np.append(fc_target,target_all_block3)  # what target is selected: 1 = low value, 2 = high value\n",
      "            counter += 1\n",
      "\n",
      "y = np.array(fc_target)\n",
      "\n",
      "it_side = np.array(it_side)\n",
      "it_reward = np.array(it_reward)\n",
      "fc_low_side = np.array(fc_low_side)\n",
      "x = np.vstack((it_side,it_reward,fc_low_side))\n",
      "x = np.transpose(x)       \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "float(sum(it_reward))/554\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 76,
       "text": [
        "0.37364620938628157"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "(156, 3)"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#x = np.array(x)\n",
      "x = sm.add_constant(x)\n",
      "results = sm.OLS(y,x).fit()\n",
      "\n",
      "\n",
      "print results.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                      y   R-squared:                       0.010\n",
        "Model:                            OLS   Adj. R-squared:                  0.005\n",
        "Method:                 Least Squares   F-statistic:                     1.870\n",
        "Date:                Sat, 28 Feb 2015   Prob (F-statistic):              0.134\n",
        "Time:                        15:14:48   Log-Likelihood:                -279.72\n",
        "No. Observations:                 554   AIC:                             567.4\n",
        "Df Residuals:                     550   BIC:                             584.7\n",
        "Df Model:                           3                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "const          0.1732      0.032      5.449      0.000         0.111     0.236\n",
        "x1            -0.0076      0.034     -0.222      0.825        -0.075     0.060\n",
        "x2             0.0834      0.035      2.359      0.019         0.014     0.153\n",
        "x3             0.0064      0.034      0.186      0.853        -0.061     0.074\n",
        "==============================================================================\n",
        "Omnibus:                      115.377   Durbin-Watson:                   1.674\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              194.205\n",
        "Skew:                           1.448   Prob(JB):                     6.74e-43\n",
        "Kurtosis:                       3.161   Cond. No.                         3.44\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results_GLS = sm.GLS(y,x).fit()\n",
      "\n",
      "\n",
      "print results_GLS.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            GLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                      y   R-squared:                       0.010\n",
        "Model:                            GLS   Adj. R-squared:                  0.005\n",
        "Method:                 Least Squares   F-statistic:                     1.870\n",
        "Date:                Sat, 28 Feb 2015   Prob (F-statistic):              0.134\n",
        "Time:                        15:15:02   Log-Likelihood:                -279.72\n",
        "No. Observations:                 554   AIC:                             567.4\n",
        "Df Residuals:                     550   BIC:                             584.7\n",
        "Df Model:                           3                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "const          0.1732      0.032      5.449      0.000         0.111     0.236\n",
        "x1            -0.0076      0.034     -0.222      0.825        -0.075     0.060\n",
        "x2             0.0834      0.035      2.359      0.019         0.014     0.153\n",
        "x3             0.0064      0.034      0.186      0.853        -0.061     0.074\n",
        "==============================================================================\n",
        "Omnibus:                      115.377   Durbin-Watson:                   1.674\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              194.205\n",
        "Skew:                           1.448   Prob(JB):                     6.74e-43\n",
        "Kurtosis:                       3.161   Cond. No.                         3.44\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}