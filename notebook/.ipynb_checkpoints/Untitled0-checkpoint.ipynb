{
 "metadata": {
  "name": "",
  "signature": "sha256:d99b9ae17dfbc3313f29c7565e8b1b34041b61f30cd6bbeba973acd29bb44f6d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd C:\\Users\\Samantha\\Documents\\GitHub\\analysis"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\Samantha\\Documents\\GitHub\\analysis\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from logLikelihoodRLPerformance import logLikelihoodRLPerformance"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tables\n",
      "import numpy as np\n",
      "hdf = tables.openFile('C:\\Users\\Samantha\\Dropbox\\Carmena Lab\\Papa\\hdf\\papa20150418_15.hdf')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Q_initial = [0.5, 0.5]\n",
      "alpha = 0.2\n",
      "beta= 0.2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "state = hdf.root.task_msgs[:]['msg']\n",
      "state_time = hdf.root.task_msgs[:]['time']\n",
      "trial_type = hdf.root.task[:]['target_index']\n",
      "# reward schedules\n",
      "reward_scheduleH = hdf.root.task[:]['reward_scheduleH']\n",
      "reward_scheduleL = hdf.root.task[:]['reward_scheduleL']\n",
      "\n",
      "\n",
      "ind_wait_states = np.ravel(np.nonzero(state == 'wait'))\n",
      "ind_target_states = np.ravel(np.nonzero(state == 'target'))\n",
      "ind_check_reward_states = np.ravel(np.nonzero(state == 'check_reward'))\n",
      "rewarded_reward_scheduleH = reward_scheduleH[state_time[ind_target_states]]\n",
      "rewarded_reward_scheduleL = reward_scheduleL[state_time[ind_target_states]]\n",
      "\n",
      "target = np.zeros(ind_check_reward_states.size)\n",
      "reward = np.zeros(target.size)\n",
      "\n",
      "'''\n",
      "Target choices for all (instructed and free-choice) and associated reward assignments\n",
      "'''\n",
      "for i in range(0,ind_check_reward_states.size):\n",
      "\ttarget_state = state[ind_check_reward_states[i] - 2]\n",
      "\tif target_state == 'hold_targetL':\n",
      "\t\ttarget[i] = 1\n",
      "\t\treward[i] = rewarded_reward_scheduleL[i]\n",
      "\telse:\n",
      "\t\ttarget[i] = 2\n",
      "\t\treward[i] = rewarded_reward_scheduleH[i]\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Q_low = Q_initial[0]\n",
      "Q_high = Q_initial[1]\n",
      "print Q_low, Q_high\n",
      "print target.size\n",
      "for i in range(0,target.size):\n",
      "    i += 2\n",
      "print i\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.5 0.5\n",
        "549\n",
        "550\n"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logLikelihoodRLPerformance(Q_initial,alpha, beta, reward,target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'str' object has no attribute 'length'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-125-3fba4557b8f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlogLikelihoodRLPerformance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Q_initial'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'alpha'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'beta'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reward'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32mC:\\Users\\Samantha\\Documents\\GitHub\\analysis\\logLikelihoodRLPerformance.py\u001b[0m in \u001b[0;36mlogLikelihoodRLPerformance\u001b[1;34m(Q_initial, alpha, beta, reward_schedule, choice)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'length'"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}